{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial for MDC tool\n",
    "\n",
    "In this notebook, it is presented a brief tutorial on how to define and train a small Convolutional Neural Network for the classification of the MNIST Dataset. At the end of the notebook, it will be showed how to convert the keras model into the QONNX format.\n",
    "\n",
    "The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image (https://yann.lecun.com/exdb/mnist/).\n",
    "\n",
    "![alt text](images/mnist_eg.png \"MNIST example\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras (https://keras.io/) is an open source free library that gives access to an interface for Neural Networks (NN) in Python. It is now integrated into the Tensorflow library.\n",
    "With Keras we have the possibility of defining and training neural networks. QKeras (https://github.com/google/qkeras) is a quantization extension to Keras that provides drop-in replacement for some of the Keras layers, especially the ones that creates parameters and activation layers, and perform arithmetic operations, so that we can quickly create a deep quantized version of Keras network.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are going to explore the capabilities of Qkeras, by defining and training a Convolutional Neural Network.\n",
    "First, we import the necessaries packages and do some checks on libraries versions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import tensorflow.compat.v2 as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a folder to store the outputs of this script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify the folder name\n",
    "folder_name = 'Mnist_Training'\n",
    "\n",
    "script_path = os.getcwd()\n",
    "# Get the current working directory\n",
    "current_directory = os.path.dirname(script_path)\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory:\", current_directory)\n",
    "\n",
    "\n",
    "# Create the full path to the new folder\n",
    "output_path = current_directory + \"/\" + folder_name\n",
    "\n",
    "# Check if the folder already exists\n",
    "if not os.path.exists(output_path):\n",
    "    # Create the folder\n",
    "    os.makedirs(output_path)\n",
    "    print(f\"Folder '{folder_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_name}' already exists.\")\n",
    "\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is time to load the MNIST dataset, and to extract information like training size (train_size), the input shape (input__shape) and the number of classes to classify (n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train, info = tfds.load('mnist', split='train[:90%]', with_info=True, as_supervised=True)\n",
    "ds_test = tfds.load('mnist', split='test', shuffle_files=True, as_supervised=True)\n",
    "ds_val = tfds.load('mnist', split='train[-10%:]', shuffle_files=True, as_supervised=True)\n",
    "\n",
    "assert isinstance(ds_train, tf.data.Dataset)\n",
    "train_size = int(info.splits['train'].num_examples)\n",
    "input_shape = info.features['image'].shape\n",
    "n_classes = info.features['label'].num_classes\n",
    "\n",
    "print('Training on {} samples of input shape {}, belonging to {} classes'.format(train_size, input_shape, n_classes))\n",
    "fig = tfds.show_examples(ds_train, info)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define a function to apply some preprocessing to the dataset and we manage the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(image, label, nclasses=10):\n",
    "    image = tf.cast(image, tf.float32) / 255.0\n",
    "    label = tf.one_hot(tf.squeeze(label), nclasses)\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1024\n",
    "\n",
    "train_data = ds_train.map(preprocess, n_classes)  # Get dataset as image and one-hot encoded labels, divided by max RGB\n",
    "train_data = train_data.shuffle(4096).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "for example in train_data.take(1):\n",
    "    break\n",
    "print(\"X train batch shape = {}, Y train batch shape = {} \".format(example[0].shape, example[1].shape))\n",
    "\n",
    "val_data = ds_val.map(preprocess, n_classes)\n",
    "val_data = val_data.batch(batch_size)\n",
    "val_data = val_data.prefetch(tf.data.experimental.AUTOTUNE)\n",
    "\n",
    "# For  testing, we get the full dataset in memory as it's rather small.\n",
    "# We fetch it as numpy arrays to have access to labels and images separately\n",
    "X_test, Y_test = tfds.as_numpy(tfds.load('mnist', split='test', batch_size=-1, as_supervised=True))\n",
    "X_test, Y_test = preprocess(X_test, Y_test, nclasses=n_classes)\n",
    "print(\"X test batch shape = {}, Y test batch shape = {} \".format(X_test.shape, Y_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we define the model: in this tutorial we are going to use a fixed architcture with customizable precision. In the create_qkeras_model we have to point out the input shape, the number of classes, and the quantized precisions for the layers of the model: first, the two Quantized Convolutional layers, then the Quantized Dense layer, and finally the Quantized Relu layers. The last layer, the Sigmoid activation function, wasn't quantized to preserve the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Flatten, MaxPooling2D, Activation\n",
    "from qkeras.qlayers import QDense, QActivation, quantized_bits, quantized_relu\n",
    "from qkeras import QConv2D\n",
    "from keras.models import Model\n",
    "from tensorflow.keras.regularizers import l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_qkeras_model(input_shape=(28, 28, 1),\n",
    "                        num_classes=10,\n",
    "                        conv1_bits=(8, 4),\n",
    "                        conv2_bits=(4, 2),\n",
    "                        dense_bits=(8, 4),\n",
    "                        activation_1_bits=(16, 8),\n",
    "                        activation_2_bits=(16, 8)):\n",
    "    \"\"\"\n",
    "    Creates the QKeras model with customizable quantization parameters.\n",
    "\n",
    "    Args:\n",
    "        input_shape (tuple): Shape of the input tensor.\n",
    "        num_classes (int): Number of output classes.\n",
    "        conv1_bits (tuple): (bits, integer) for the first QConv2D layer.\n",
    "        conv2_bits (tuple): (bits, integer) for the second QConv2D layer.\n",
    "        dense_bits (tuple): (bits, integer) for the QDense layer.\n",
    "        activation_bits (tuple): (bits, integer) for QActivation layers.\n",
    "\n",
    "    Returns:\n",
    "        qmodel: The QKeras model.\n",
    "    \"\"\"\n",
    "    # Input layer\n",
    "    x = x_in = Input(shape=input_shape, name=\"input_layer\")\n",
    "\n",
    "    # First QConv2D layer\n",
    "    x = QConv2D(\n",
    "        32, (3, 3), name=\"q_conv2d\", padding=\"same\",\n",
    "        kernel_quantizer=quantized_bits(bits=conv1_bits[0], integer=conv1_bits[1], alpha=1),\n",
    "        bias_quantizer=quantized_bits(bits=conv1_bits[0], integer=conv1_bits[1], alpha=1)\n",
    "    )(x)\n",
    "    x = QActivation(\n",
    "        quantized_relu(bits=activation_1_bits[0], integer=activation_1_bits[1], use_sigmoid=0, negative_slope=0.0),\n",
    "        name=\"act_1\"\n",
    "    )(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name=\"max_pool_1\")(x)\n",
    "\n",
    "    # Second QConv2D layer\n",
    "    x = QConv2D(\n",
    "        32, (3, 3), name=\"q_conv2d_1\", padding=\"same\",\n",
    "        kernel_quantizer=quantized_bits(bits=conv2_bits[0], integer=conv2_bits[1], alpha=1),\n",
    "        bias_quantizer=quantized_bits(bits=conv2_bits[0], integer=conv2_bits[1], alpha=1)\n",
    "    )(x)\n",
    "    x = QActivation(\n",
    "        quantized_relu(bits=activation_2_bits[0], integer=activation_2_bits[1], use_sigmoid=0, negative_slope=0.0),\n",
    "        name=\"act_2\"\n",
    "    )(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2), name=\"max_pool_2\")(x)\n",
    "\n",
    "    # Flatten and Dense layer\n",
    "    x = Flatten(name=\"flatten\")(x)\n",
    "    x = QDense(\n",
    "        num_classes, name=\"q_dense\",\n",
    "        kernel_quantizer=quantized_bits(bits=dense_bits[0], integer=dense_bits[1], alpha=1),\n",
    "        bias_quantizer=quantized_bits(bits=dense_bits[0], integer=dense_bits[1], alpha=1)\n",
    "    )(x)\n",
    "\n",
    "    # Output layer\n",
    "    x_out = Activation(\"sigmoid\", name=\"output_sigmoid\")(x)\n",
    "\n",
    "    # Create model\n",
    "    qmodel = Model(inputs=[x_in], outputs=[x_out], name=\"qkeras\")\n",
    "\n",
    "    return qmodel\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "qmodel = create_qkeras_model(input_shape=(28, 28, 1),\n",
    "                        num_classes=10,\n",
    "                        conv1_bits=(8, 4),\n",
    "                        conv2_bits=(4, 2),\n",
    "                        dense_bits=(8, 4),\n",
    "                        activation_1_bits=(16, 8),\n",
    "                        activation_2_bits=(16, 8))\n",
    "qmodel.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the training phase can start. A low number of epochs is chosen as the model is fairly small and simple, leading to a short training time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = True\n",
    "\n",
    "n_epochs = 3\n",
    "if train:\n",
    "    LOSS = tf.keras.losses.CategoricalCrossentropy()\n",
    "    OPTIMIZER = tf.keras.optimizers.Adam(learning_rate=3e-3, beta_1=0.9, beta_2=0.999, epsilon=1e-07, amsgrad=True)\n",
    "    qmodel.compile(loss=LOSS, optimizer=OPTIMIZER, metrics=[\"accuracy\"])\n",
    "\n",
    "    callbacks = [\n",
    "        tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "    ]\n",
    "\n",
    "    start = time.time()\n",
    "    history = qmodel.fit(train_data, epochs=n_epochs, validation_data=val_data, callbacks=callbacks, verbose=1)\n",
    "    end = time.time()\n",
    "    print('\\n It took {} minutes to train!\\n'.format((end - start) / 60.0))\n",
    "\n",
    "    qmodel.save('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, the keras model can be converted into the QONNX format. The QONNX format is an exstension of ONNX, an open format built to represent machine learning models. ONNX defines a common set of operators - the building blocks of machine learning and deep learning models - and a common file format to enable AI developers to use models with a variety of frameworks, tools, runtimes, and compilers (https://onnx.ai/).\n",
    "\n",
    "QONNX (Quantized ONNX), starting from ONNX, introduces three new custom operators, Quant, BipolarQuant, and Trunc, in order to represent arbitrary-precision uniform quantization in ONNX. This enables representation of binary, ternary, 3-bit, 4-bit, 6-bit or any other quantization (https://github.com/fastmachinelearning/qonnx)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qonnx.converters import from_keras\n",
    "\n",
    "path = output_path + '/qonnx_model.onnx'\n",
    "print(\"conversion to qonnx...\")\n",
    "qonnx_model, _  = from_keras(\n",
    "    qmodel,\n",
    "    name=\"qkeras_to_qonnx_converted\",\n",
    "    input_signature=None,\n",
    "    opset=None,\n",
    "    custom_ops=None,\n",
    "    custom_op_handlers=None,\n",
    "    custom_rewriter=None,\n",
    "    inputs_as_nchw=None,\n",
    "    extra_opset=None,\n",
    "    shape_override=None,\n",
    "    target=None,\n",
    "    large_model=False,\n",
    "    output_path = path,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hls4ml-tutorial",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
