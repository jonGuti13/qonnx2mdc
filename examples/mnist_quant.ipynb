{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Keras (https://keras.io/) is an open source free library that gives access to an interface for Neural Networks (NN) in Python. It is now integrated into the Tensorflow library.\n",
    "With Keras we have the possibility of defining and training neural networks. QKeras (https://github.com/google/qkeras) is a quantization extension to Keras that provides drop-in replacement for some of the Keras layers, especially the ones that creates parameters and activation layers, and perform arithmetic operations, so that we can quickly create a deep quantized version of Keras network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we are going to explore the capabilities of Qkeras, by defining and training a Convolutional Neural Network.\n",
    "First, we import the necessaries packages and do some checks on libraries versions and GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 09:39:30.386143: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.13.0\n",
      "QKeras version: 0.9.0\n",
      "Keras version: 2.13.1\n",
      "Num GPUs Available:  0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import tensorflow as tf\n",
    "import qkeras\n",
    "tf.keras.backend.clear_session()\n",
    "print(\"TensorFlow version:\", tf.__version__)\n",
    "print(\"QKeras version:\", qkeras.__version__)\n",
    "print(\"Keras version:\", keras.__version__)\n",
    "import os\n",
    "\n",
    "#If available, use GPU\n",
    "print(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then create some useful directories where we can store the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: /home/fede/Assegno_UNISS/budva_2024\n",
      "Folder 'Mnist_Training' already exists.\n",
      "/home/fede/Assegno_UNISS/budva_2024/Mnist_Training\n"
     ]
    }
   ],
   "source": [
    "# Specify the folder name\n",
    "folder_name = 'Mnist_Training'\n",
    "\n",
    "script_path = os.getcwd()\n",
    "# Get the current working directory\n",
    "current_directory = os.path.dirname(script_path)\n",
    "\n",
    "# Print the current working directory\n",
    "print(\"Current working directory:\", current_directory)\n",
    "\n",
    "\n",
    "# Create the full path to the new folder\n",
    "output_path = current_directory + \"/\" + folder_name\n",
    "\n",
    "# Check if the folder already exists\n",
    "if not os.path.exists(output_path):\n",
    "    # Create the folder\n",
    "    os.makedirs(output_path)\n",
    "    print(f\"Folder '{folder_name}' created successfully.\")\n",
    "else:\n",
    "    print(f\"Folder '{folder_name}' already exists.\")\n",
    "\n",
    "print(output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are defined some flags. We can select the type of quantization we want and if we desire to convert the model to onnx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#.......FLAGS.........\n",
    "mnist_baseline = False\n",
    "mnist16_8 = False\n",
    "mnist16_4 = True\n",
    "mnist8_8 = False\n",
    "mnist8_4 = False\n",
    "mnist4_4 = False\n",
    "mnist4_2 = False\n",
    "mnist2_2 = False\n",
    "mnist_bin = False\n",
    "\n",
    "#This flag is responsible for the activation or deactivation of the transformation of the qkeras model to a qonnx model\n",
    "convert_to_qonnx = True\n",
    "\n",
    "#........................."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we import the Mnist Dataset, the Sequential for defining a sequential keras model, some layers needed to define the neural network. We then pre-process the mnist dataset by normalizing it, reshaping it and finally, whe apply the categorical function which gives a more desirable form to the classes for the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import mnist\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import MaxPool2D, Conv2D, Flatten, Dense, Activation\n",
    "\n",
    "\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Prepare the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "mnist_input_shape = (1,28,28,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are defined the different models. Each model has some different kernel_quantizers and bias_quantizers, which are functions that apply the quantization to, respectively, weights and biases of the Conv and Gemm layers, and QActivations, which quantizes the activations. While all the Relu layers are quantized, even if with different precisions for each model, we always left untouched the last activation, the Sigmoid layer, to have a better accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 09:44:46.681073: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "/home/fede/miniconda3/envs/venv4qonnx/lib/python3.8/site-packages/keras/src/initializers/initializers.py:120: UserWarning: The initializer HeNormal is unseeded and being called multiple times, which will return identical values each time (even if the initializer is unseeded). Please update your code to provide a seed to the initializer, or avoid using the same initializer instance more than once.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "422/422 [==============================] - 48s 111ms/step - loss: 25.8461 - accuracy: 0.3376 - val_loss: 1.2612 - val_accuracy: 0.6722\n",
      "Epoch 2/2\n",
      "422/422 [==============================] - 48s 114ms/step - loss: 2.5238 - accuracy: 0.4017 - val_loss: 1.2028 - val_accuracy: 0.6067\n"
     ]
    }
   ],
   "source": [
    "            \n",
    "\n",
    "if mnist_baseline:\n",
    "\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(Conv2D(32, (3,3), padding='same', activation='relu', input_shape=mnist_input_shape[1:]))\n",
    "    model.add(MaxPool2D(pool_size=(2, 2)))\n",
    "    model.add(Conv2D(64, (3,3), padding='same', activation='relu'))\n",
    "    model.add(MaxPool2D(pool_size=(2,2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.7))\n",
    "    model.add(Dense(10,activation = \"sigmoid\"))\n",
    "\n",
    "    batch_size = 128\n",
    "    epochs = 15\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "        model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "        model.save( output_path +'/mnist_baseline.keras')\n",
    "\n",
    "elif mnist16_8:\n",
    "\n",
    "    from keras.layers import *\n",
    "    from qkeras import *\n",
    "    from qkeras.qlayers import QDense, QActivation, quantized_bits, quantized_relu\n",
    "    from qkeras import QConv2D\n",
    "    from keras.models import Model\n",
    "\n",
    "    x = x_in = Input(mnist_input_shape[1:])\n",
    "\n",
    "    x = (QConv2D(32, (3,3), padding='same',kernel_quantizer= quantized_bits(bits=8, integer=4, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=8, integer=4, alpha=1)))(x)\n",
    "    x =(QActivation(quantized_relu(bits=16, integer=8, use_sigmoid=0, negative_slope=0.0), name=\"act_1\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(QConv2D(32, (3,3), padding='same',kernel_quantizer= quantized_bits(bits=8, integer=4, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=8, integer=4, alpha=1)))(x)\n",
    "    x =(QActivation(quantized_relu(bits=16, integer=8, use_sigmoid=0, negative_slope=0.0), name=\"act_2\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(Flatten())(x)\n",
    "    x =(Dropout(0.5))(x)\n",
    "    x = QDense((10),kernel_quantizer= quantized_bits(bits=8, integer=4, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=8, integer=4, alpha=1)) (x)   # num_classes = 10\n",
    "    x =(Activation(activation='sigmoid', name='out_activation'))(x)\n",
    "\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "\n",
    "    batch_size = 128\n",
    "    epochs = 15\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "        model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "        model.save( output_path +'/mnist16_8.keras')\n",
    "    \n",
    "elif mnist16_4:\n",
    "\n",
    "    from keras.layers import *\n",
    "    from qkeras import *\n",
    "    from qkeras.qlayers import QDense, QActivation, quantized_bits, quantized_relu\n",
    "    from qkeras import QConv2D\n",
    "    from keras.models import Model\n",
    "\n",
    "    x = x_in = Input(mnist_input_shape[1:])\n",
    "\n",
    "    x = (QConv2D(32, (3,3), padding='same',kernel_quantizer= quantized_bits(bits=4, integer=2, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=4, integer=2, alpha=1)))(x)\n",
    "    x =(QActivation(quantized_relu(bits=16, integer=8, use_sigmoid=0, negative_slope=0.0), name=\"act_1\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(QConv2D(32, (3,3), padding='same',kernel_quantizer= quantized_bits(bits=4, integer=2, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=4, integer=2, alpha=1)))(x)\n",
    "    x =(QActivation(quantized_relu(bits=16, integer=8, use_sigmoid=0, negative_slope=0.0), name=\"act_2\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(Flatten())(x)\n",
    "    x =(Dropout(0.6))(x)\n",
    "    x = QDense((10),kernel_quantizer= quantized_bits(bits=4, integer=2, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=4, integer=2, alpha=1)) (x)   # num_classes = 10\n",
    "    x =(Activation(activation='sigmoid', name='out_activation'))(x)\n",
    "\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "\n",
    "    batch_size = 128\n",
    "    epochs = 2\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "        model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "        model.save( output_path +'/mnist16_4.keras')\n",
    "\n",
    "elif mnist8_8:\n",
    "\n",
    "    from keras.layers import *\n",
    "    from qkeras import *\n",
    "    from qkeras.qlayers import QDense, QActivation, quantized_bits, quantized_relu\n",
    "    from qkeras import QConv2D\n",
    "    from keras.models import Model\n",
    "\n",
    "    x = x_in = Input(mnist_input_shape[1:])\n",
    "\n",
    "    x = (QConv2D(32, (3,3), padding='same',kernel_quantizer= quantized_bits(bits=8, integer=4, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=8, integer=4, alpha=1)))(x)\n",
    "    x =(QActivation(quantized_relu(bits=8, integer=4, use_sigmoid=0, negative_slope=0.0), name=\"act_1\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(QConv2D(32, (3,3), padding='same',kernel_quantizer= quantized_bits(bits=4, integer=2, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=4, integer=2, alpha=1)))(x)\n",
    "    x =(QActivation(quantized_relu(bits=4, integer=2, use_sigmoid=0, negative_slope=0.0), name=\"act_2\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(Flatten())(x)\n",
    "    x =(Dropout(0.5))(x)\n",
    "    x = QDense((10),kernel_quantizer= quantized_bits(bits=8, integer=4, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=8, integer=4, alpha=1)) (x)   # num_classes = 10\n",
    "    x =(Activation(activation='sigmoid', name='out_activation'))(x)\n",
    "\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "\n",
    "    batch_size = 128\n",
    "    epochs = 15\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "        model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "        model.save( output_path +'/mnist8_8_mxd.keras')\n",
    "\n",
    "elif mnist8_4:\n",
    "\n",
    "    from keras.layers import *\n",
    "    from qkeras import *\n",
    "    from qkeras.qlayers import QDense, QActivation, quantized_bits, quantized_relu\n",
    "    from qkeras import QConv2D\n",
    "    from keras.models import Model\n",
    "\n",
    "    x = x_in = Input(mnist_input_shape[1:])\n",
    "\n",
    "    x = (QConv2D(32, (3,3), padding='same',kernel_quantizer= quantized_bits(bits=4, integer=2, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=4, integer=2, alpha=1)))(x)\n",
    "    x =(QActivation(quantized_relu(bits=8, integer=4, use_sigmoid=0, negative_slope=0.0), name=\"act_1\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(QConv2D(32, (3,3), padding='same',kernel_quantizer= quantized_bits(bits=4, integer=2, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=4, integer=2, alpha=1)))(x)\n",
    "    x =(QActivation(quantized_relu(bits=8, integer=4, use_sigmoid=0, negative_slope=0.0), name=\"act_2\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(Flatten())(x)\n",
    "    x =(Dropout(0.5))(x)\n",
    "    x = QDense((10),kernel_quantizer= quantized_bits(bits=4, integer=2, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=4, integer=2, alpha=1)) (x)   # num_classes = 10\n",
    "    x =(Activation(activation='sigmoid', name='out_activation'))(x)\n",
    "\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "\n",
    "    batch_size = 128\n",
    "    epochs = 15\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "        model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "        model.save( output_path +'/mnist8_4.keras')\n",
    "\n",
    "elif mnist4_4:\n",
    "\n",
    "    from keras.layers import *\n",
    "    from qkeras import *\n",
    "    from qkeras.qlayers import QDense, QActivation, quantized_bits, quantized_relu\n",
    "    from qkeras import QConv2D\n",
    "    from keras.models import Model\n",
    "\n",
    "    x = x_in = Input(mnist_input_shape[1:])\n",
    "\n",
    "    x = (QConv2D(32, (3,3), padding='same',kernel_quantizer= quantized_bits(bits=4, integer=2, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=4, integer=2, alpha=1)))(x)\n",
    "    x =(QActivation(quantized_relu(bits=4, integer=2, use_sigmoid=0, negative_slope=0.0), name=\"act_1\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(QConv2D(32, (3,3), padding='same',kernel_quantizer= quantized_bits(bits=4, integer=2, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=4, integer=2, alpha=1)))(x)\n",
    "    x =(QActivation(quantized_relu(bits=4, integer=2, use_sigmoid=0, negative_slope=0.0), name=\"act_2\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(Flatten())(x)\n",
    "    x =(Dropout(0.5))(x)\n",
    "    x = QDense((10),kernel_quantizer= quantized_bits(bits=4, integer=2, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=4, integer=2, alpha=1)) (x)   # num_classes = 10\n",
    "    x =(Activation(activation='sigmoid', name='out_activation'))(x)\n",
    "\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "\n",
    "    batch_size = 128\n",
    "    epochs = 40\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "        model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)\n",
    "\n",
    "        model.save( output_path +'/mnist4_4.keras')\n",
    "\n",
    "elif mnist4_2:\n",
    "\n",
    "    from keras.layers import *\n",
    "    from qkeras import *\n",
    "    from qkeras.qlayers import QDense, QActivation, quantized_bits, quantized_relu\n",
    "    from qkeras import QConv2D\n",
    "    from keras.models import Model\n",
    "    from keras.optimizers import Adam\n",
    "    from keras.callbacks import EarlyStopping\n",
    "\n",
    "    weight_decay = 0\n",
    "    x = x_in = Input(mnist_input_shape[1:])\n",
    "\n",
    "    x = (QConv2D(32, (3,3), padding='same',kernel_quantizer= quantized_bits(bits=2, integer=1, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=2, integer=1, alpha=1),kernel_regularizer=regularizers.l2(weight_decay)))(x)\n",
    "    x =(QActivation(quantized_relu(bits=4, integer=2, use_sigmoid=0, negative_slope=0.0), name=\"act_1\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(QConv2D(32, (3,3), padding='same',kernel_quantizer= quantized_bits(bits=2, integer=1, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=2, integer=1, alpha=1),kernel_regularizer=regularizers.l2(weight_decay)))(x)\n",
    "    x =(QActivation(quantized_relu(bits=4, integer=2, use_sigmoid=0, negative_slope=0.0), name=\"act_2\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(Flatten())(x)\n",
    "    x =(Dropout(0.05))(x)\n",
    "    x = QDense((10),kernel_quantizer= quantized_bits(bits=2, integer=1, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=2, integer=1, alpha=1),kernel_regularizer=regularizers.l2(weight_decay)) (x)   # num_classes = 10\n",
    "    x =(Activation(activation='sigmoid', name='out_activation'))(x)\n",
    "\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "\n",
    "    batch_size = 128\n",
    "    epochs = 40\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate = 0.001), metrics=[\"accuracy\"])\n",
    "        early_stopping_monitor = EarlyStopping(\n",
    "                                        monitor='accuracy',\n",
    "                                        min_delta=0,\n",
    "                                        patience=4,\n",
    "                                        verbose=0,\n",
    "                                        mode='auto',\n",
    "                                        baseline=None,\n",
    "                                        restore_best_weights=True\n",
    "                                    )\n",
    "\n",
    "        model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.25, callbacks = [early_stopping_monitor])\n",
    "\n",
    "        model.save( output_path +'/mnist4_2.keras')\n",
    "\n",
    "elif mnist2_2:\n",
    "\n",
    "    from keras.layers import *\n",
    "    from qkeras import *\n",
    "    from qkeras.qlayers import QDense, QActivation, quantized_bits, quantized_relu\n",
    "    from qkeras import QConv2D\n",
    "    from keras.models import Model\n",
    "    from keras.optimizers import Adam\n",
    "\n",
    "    weight_decay = 0\n",
    "    x = x_in = Input(mnist_input_shape[1:])\n",
    "\n",
    "    x = (QConv2D(32, (3,3), padding='same',kernel_quantizer= quantized_bits(bits=2, integer=1, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=2, integer=1, alpha=1),kernel_regularizer=regularizers.l2(weight_decay)))(x)\n",
    "    x =(QActivation(quantized_relu(bits=2, integer=1, use_sigmoid=0, negative_slope=0.0), name=\"act_1\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(QConv2D(32, (3,3), padding='same',kernel_quantizer= quantized_bits(bits=2, integer=1, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=2, integer=1, alpha=1),kernel_regularizer=regularizers.l2(weight_decay)))(x)\n",
    "    x =(QActivation(quantized_relu(bits=2, integer=1, use_sigmoid=0, negative_slope=0.0), name=\"act_2\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(Flatten())(x)\n",
    "    #x =(Dropout(0.3))(x)\n",
    "    x = QDense((10),kernel_quantizer= quantized_bits(bits=16, integer=8, alpha=1),\n",
    "        bias_quantizer= quantized_bits(bits=2, integer=1, alpha=1),kernel_regularizer=regularizers.l2(weight_decay)) (x)   # num_classes = 10\n",
    "    x =(Activation(activation='sigmoid', name='out_activation'))(x)\n",
    "\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "\n",
    "    batch_size = 128\n",
    "    epochs = 40\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=Adam(learning_rate = 0.01), metrics=[\"accuracy\"])\n",
    "\n",
    "        model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.25)\n",
    "\n",
    "        model.save( output_path +'/mnist_mxd_16_2.keras')\n",
    "\n",
    "elif mnist_bin:\n",
    "\n",
    "    from keras.layers import *\n",
    "    from qkeras import *\n",
    "    from qkeras.qlayers import QDense, QActivation, quantized_bits, quantized_relu\n",
    "    from qkeras import QConv2D\n",
    "    from keras.models import Model\n",
    "\n",
    "    x = x_in = Input(mnist_input_shape[1:])\n",
    "\n",
    "    x = (QConv2D(32, (3,3), padding='same',kernel_quantizer= binary(use_01=False, alpha=1, use_stochastic_rounding=False),\n",
    "        bias_quantizer= binary(use_01=False, alpha=1, use_stochastic_rounding=False)))(x)\n",
    "    x =(QActivation(binary(use_01=False, alpha=1, use_stochastic_rounding=False), name=\"act_1\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(QConv2D(32, (3,3), padding='same',kernel_quantizer= binary(use_01=False, alpha=1, use_stochastic_rounding=False),\n",
    "        bias_quantizer= binary(use_01=False, alpha=1, use_stochastic_rounding=False)))(x)\n",
    "    x =(QActivation(binary(use_01=False, alpha=1, use_stochastic_rounding=False), name=\"act_2\"))(x)\n",
    "    x =(MaxPool2D(pool_size=(2,2)))(x)\n",
    "    x =(Flatten())(x)\n",
    "    x =(Dropout(0.5))(x)\n",
    "    x = QDense((10),kernel_quantizer= binary(use_01=False, alpha=1, use_stochastic_rounding=False),\n",
    "        bias_quantizer= binary(use_01=False, alpha=1, use_stochastic_rounding=False)) (x)   # num_classes = 10\n",
    "    x =(Activation(activation='sigmoid', name='out_activation'))(x)\n",
    "\n",
    "    model = Model(inputs=x_in, outputs=x)\n",
    "\n",
    "    callbacks = [\n",
    "            tf.keras.callbacks.EarlyStopping(patience=10, verbose=1),\n",
    "            tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, verbose=1),\n",
    "        ]\n",
    "\n",
    "    batch_size = 128\n",
    "    epochs = 60\n",
    "\n",
    "    with tf.device('/GPU:0'):\n",
    "        model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "        model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1, callbacks = callbacks)\n",
    "\n",
    "        model.save( output_path +'/mnist_binary_1.keras')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this last section we can decide to apply the transformation of the keras model into an onnx model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tf2onnx.tf_loader:Could not search for non-variable resources. Concrete function internal representation may have changed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conversion to qonnx...\n",
      "from_keras conversion\n",
      "calling convert_common\n",
      "convert_common\n",
      "trying rewriter: <function rewrite_conv2d_with_pad at 0x7ff211b5a1f0>\n",
      "trying rewriter: <function rewrite_constant_fold at 0x7ff211acdd30>\n",
      "trying rewriter: <function rewrite_quantize_and_dequantize at 0x7ff211b22d30>\n",
      "trying rewriter: <function rewrite_fused_ops at 0x7ff211b2b0d0>\n",
      "trying rewriter: <function rewrite_transpose at 0x7ff211b229d0>\n",
      "trying rewriter: <function rewrite_flatten at 0x7ff211b60b80>\n",
      "trying rewriter: <function rewrite_random_uniform at 0x7ff211b640d0>\n",
      "trying rewriter: <function rewrite_random_uniform_fold_const at 0x7ff211b64160>\n",
      "trying rewriter: <function rewrite_random_normal at 0x7ff211b60e50>\n",
      "trying rewriter: <function rewrite_dropout at 0x7ff211b60a60>\n",
      "trying rewriter: <function rewrite_conv_dilations at 0x7ff211b5ae50>\n",
      "trying rewriter: <function rewrite_eye at 0x7ff211b60af0>\n",
      "trying rewriter: <function rewrite_leakyrelu at 0x7ff211b60d30>\n",
      "trying rewriter: <function rewrite_thresholded_relu at 0x7ff211b228b0>\n",
      "trying rewriter: <function rewriter_lstm_tf2 at 0x7ff211b22f70>\n",
      "trying rewriter: <function rewrite_gru_tf2 at 0x7ff211b2b040>\n",
      "trying rewriter: <function rewrite_single_direction_lstm at 0x7ff211b643a0>\n",
      "trying rewriter: <function rewrite_bi_direction_lstm at 0x7ff211b0f940>\n",
      "trying rewriter: <function rewrite_single_direction_gru at 0x7ff211b1de50>\n",
      "trying rewriter: <function rewrite_bi_direction_gru at 0x7ff211b22670>\n",
      "trying rewriter: <function rewrite_custom_rnn_cell at 0x7ff211b22700>\n",
      "trying rewriter: <function rewrite_generic_loop at 0x7ff211b22790>\n",
      "trying rewriter: <function rewrite_cond at 0x7ff211b5a3a0>\n",
      "trying rewriter: <function rewrite_biasadd_with_conv2d at 0x7ff211b22a60>\n",
      "trying rewriter: <function rewrite_layer_normalization at 0x7ff211b22af0>\n",
      "trying rewriter: <function rewrite_gemm at 0x7ff211b60c10>\n",
      "trying rewriter: <function rewrite_ragged_variant_shape at 0x7ff211b22e50>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-18 09:48:06.793797: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-09-18 09:48:06.796690: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n",
      "2024-09-18 09:48:06.823098: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n",
      "2024-09-18 09:48:06.825440: I tensorflow/core/grappler/devices.cc:75] Number of eligible GPUs (core count >= 8, compute capability >= 0.0): 0 (Note: TensorFlow was not compiled with CUDA or ROCm support)\n",
      "2024-09-18 09:48:06.825525: I tensorflow/core/grappler/clusters/single_machine.cc:357] Starting new session\n"
     ]
    }
   ],
   "source": [
    "\n",
    "if convert_to_qonnx:\n",
    "\n",
    "    from qonnx.converters import from_keras\n",
    "\n",
    "    #we have ptq_model, converted in qkeras, and k_model, just in keras \n",
    "\n",
    "    path = output_path +'/qonnx_model.onnx'\n",
    "    print(\"conversion to qonnx...\")\n",
    "    qonnx_model, _  = from_keras(\n",
    "        model,\n",
    "        name=\"qkeras_to_qonnx_converted\",\n",
    "        input_signature=None,\n",
    "        opset=None,\n",
    "        custom_ops=None,\n",
    "        custom_op_handlers=None,\n",
    "        custom_rewriter=None,\n",
    "        inputs_as_nchw=None,\n",
    "        extra_opset=None,\n",
    "        shape_override=None,\n",
    "        target=None,\n",
    "        large_model=False,\n",
    "        output_path = path,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
